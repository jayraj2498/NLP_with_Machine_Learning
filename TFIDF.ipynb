{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of artificial intelligence (AI) \n",
    "that focuses on the interaction between computers and humans through natural language. \n",
    "It involves the development of algorithms and models to understand, interpret, and \n",
    "generate human-like language.\n",
    "\n",
    "Tokenization is an important step in NLP. It involves breaking down text into individual words or tokens. \n",
    "After tokenization, lemmatization can be applied to reduce words to their base form. \n",
    "Stopwords, common words that don't carry much meaning, are often removed during preprocessing.\n",
    "\n",
    "NLP techniques, such as one-hot encoding, bag-of-words, and TF-IDF, help convert text data into a format \n",
    "that can be used by machine learning models. Word embeddings, such as Word2Vec and GloVe, provide \n",
    "dense vector representations for words, capturing semantic relationships.\n",
    "\n",
    "Understanding these techniques is crucial for working with text data and building effective NLP applications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Representation\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_representation = tfidf_vectorizer.fit_transform([processed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['ai' 'algorithm' 'application' 'applied' 'artificial' 'bag' 'base'\n",
      " 'breaking' 'building' 'capturing' 'carry' 'common' 'computer' 'convert'\n",
      " 'crucial' 'data' 'dense' 'development' 'effective' 'embeddings'\n",
      " 'encoding' 'focus' 'form' 'format' 'generate' 'glove' 'help' 'hot'\n",
      " 'human' 'idf' 'important' 'individual' 'intelligence' 'interaction'\n",
      " 'interpret' 'involves' 'language' 'learning' 'lemmatization' 'like'\n",
      " 'machine' 'meaning' 'model' 'much' 'natural' 'nlp' 'of' 'often' 'one'\n",
      " 'preprocessing' 'processing' 'provide' 'reduce' 'relationship' 'removed'\n",
      " 'representation' 'semantic' 'step' 'stopwords' 'subfield' 'technique'\n",
      " 'text' 'tf' 'token' 'tokenization' 'understand' 'understanding' 'used'\n",
      " 'vector' 'word' 'word2vec' 'words' 'working']\n",
      "\n",
      "\n",
      "TF-IDF Representation:\n",
      " [[0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.16384638 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.16384638 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.16384638\n",
      "  0.24576958 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.16384638 0.08192319 0.16384638 0.32769277 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.08192319 0.08192319 0.08192319\n",
      "  0.16384638 0.24576958 0.08192319 0.08192319 0.16384638 0.08192319\n",
      "  0.08192319 0.08192319 0.08192319 0.40961596 0.08192319 0.08192319\n",
      "  0.08192319]]\n"
     ]
    }
   ],
   "source": [
    "# Print the vocabulary and TF-IDF representation\n",
    "vocabulary = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\", vocabulary) \n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"TF-IDF Representation:\\n\", tfidf_representation.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
