{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of artificial intelligence (AI) \n",
    "that focuses on the interaction between computers and humans through natural language. \n",
    "It involves the development of algorithms and models to understand, interpret, and \n",
    "generate human-like language.\n",
    "\n",
    "Tokenization is an important step in NLP. It involves breaking down text into individual words or tokens. \n",
    "After tokenization, lemmatization can be applied to reduce words to their base form. \n",
    "Stopwords, common words that don't carry much meaning, are often removed during preprocessing.\n",
    "\n",
    "NLP techniques, such as one-hot encoding, bag-of-words, and TF-IDF, help convert text data into a format \n",
    "that can be used by machine learning models. Word embeddings, such as Word2Vec and GloVe, provide \n",
    "dense vector representations for words, capturing semantic relationships.\n",
    "\n",
    "Understanding these techniques is crucial for working with text data and building effective NLP applications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token.lower() for token in lemmatized_tokens if token.lower() not in stop_words and token not in punctuation]\n",
    "\n",
    "\n",
    "\n",
    "# Convert the list of tokens into a string (required for CountVectorizer)\n",
    "processed_text = ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words Representation\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform([processed_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x73 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 73 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['ai' 'algorithm' 'application' 'applied' 'artificial' 'bag' 'base'\n",
      " 'breaking' 'building' 'capturing' 'carry' 'common' 'computer' 'convert'\n",
      " 'crucial' 'data' 'dense' 'development' 'effective' 'embeddings'\n",
      " 'encoding' 'focus' 'form' 'format' 'generate' 'glove' 'help' 'hot'\n",
      " 'human' 'idf' 'important' 'individual' 'intelligence' 'interaction'\n",
      " 'interpret' 'involves' 'language' 'learning' 'lemmatization' 'like'\n",
      " 'machine' 'meaning' 'model' 'much' 'natural' 'nlp' 'of' 'often' 'one'\n",
      " 'preprocessing' 'processing' 'provide' 'reduce' 'relationship' 'removed'\n",
      " 'representation' 'semantic' 'step' 'stopwords' 'subfield' 'technique'\n",
      " 'text' 'tf' 'token' 'tokenization' 'understand' 'understanding' 'used'\n",
      " 'vector' 'word' 'word2vec' 'words' 'working']\n",
      "Bag-of-Words Representation:\n",
      " [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2\n",
      "  3 1 1 1 1 1 2 1 2 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 1 1 2 1 1 1 1 5 1 1\n",
      "  1]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "print(\"Bag-of-Words Representation:\\n\", bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_reviews = [\"I loved the movie. The storyline was amazing.\",\n",
    "                    \"Great acting and a compelling plot.\",\n",
    "                    \"One of the best movies I've seen in years.\"]\n",
    "\n",
    "negative_reviews = [\"The movie was terrible. I didn't enjoy it at all.\",\n",
    "                    \"Poor acting and a confusing storyline.\",\n",
    "                    \"I regret watching this film.\"]\n",
    "\n",
    "labels = [1] * len(positive_reviews) + [0] * len(negative_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine positive and negative reviews\n",
    "all_reviews = positive_reviews + negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I loved the movie. The storyline was amazing.',\n",
       " 'Great acting and a compelling plot.',\n",
       " \"One of the best movies I've seen in years.\",\n",
       " \"The movie was terrible. I didn't enjoy it at all.\",\n",
       " 'Poor acting and a confusing storyline.',\n",
       " 'I regret watching this film.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenization, lemmatization, and removal of stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.lower() not in stop_words and token not in punctuation]\n",
    "    return ' '.join(processed_tokens) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply preprocessing to all reviews\n",
    "processed_reviews = [preprocess_text(review) for review in all_reviews]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Bag-of-Words Representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Text Classification\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       2.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small project with with BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  review\n",
      "0       Thoroughly enjoyed every moment of the film.       1\n",
      "1  The movie was overhyped and did not live up to...       0\n",
      "2                Great acting and a compelling plot.       1\n",
      "3                  A heartwarming and touching film.       1\n",
      "4      A masterpiece of storytelling and filmmaking.       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Generate synthetic data for positive and negative reviews\n",
    "positive_reviews = [\n",
    "    \"I loved the movie. The storyline was amazing.\",\n",
    "    \"Great acting and a compelling plot.\",\n",
    "    \"One of the best movies I've seen in years.\",\n",
    "    \"Amazing cinematography and excellent performances.\",\n",
    "    \"A heartwarming and touching film.\",\n",
    "    \"The characters were well-developed, and the dialogue was engaging.\",\n",
    "    \"A must-watch for all movie enthusiasts.\",\n",
    "    \"I couldn't get enough of this movie. Highly recommended.\",\n",
    "    \"Thoroughly enjoyed every moment of the film.\",\n",
    "    \"The director did a fantastic job bringing the story to life.\",\n",
    "    \"Incredible visual effects and a gripping narrative.\",\n",
    "    \"A masterpiece of storytelling and filmmaking.\",\n",
    "    \"The soundtrack added a lot to the overall experience.\",\n",
    "    \"An instant classic. I will definitely watch it again.\",\n",
    "    \"The movie exceeded my expectations. A true gem.\",\n",
    "    \"A brilliant and thought-provoking piece of cinema.\",\n",
    "    \"I was on the edge of my seat throughout the entire film.\",\n",
    "    \"The humor in the movie was spot-on and had me laughing non-stop.\",\n",
    "    \"The twists and turns kept me guessing until the end.\",\n",
    "    \"Fantastic chemistry among the cast members.\",\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"The movie was terrible. I didn't enjoy it at all.\",\n",
    "    \"Poor acting and a confusing storyline.\",\n",
    "    \"I regret watching this film.\",\n",
    "    \"Disappointing and predictable. Not worth the hype.\",\n",
    "    \"Lackluster performances and a weak plot.\",\n",
    "    \"I found it boring and uninteresting.\",\n",
    "    \"The characters were poorly developed.\",\n",
    "    \"A complete waste of time. I wouldn't recommend it.\",\n",
    "    \"The dialogue felt forced, and the pacing was off.\",\n",
    "    \"I expected more from this movie, but it fell short.\",\n",
    "    \"The film lacked originality and creativity.\",\n",
    "    \"I couldn't connect with the characters.\",\n",
    "    \"The special effects were subpar.\",\n",
    "    \"I was disappointed by the lack of depth in the story.\",\n",
    "    \"The movie was overhyped and did not live up to expectations.\",\n",
    "    \"A letdown from start to finish.\",\n",
    "    \"I couldn't wait for it to be over.\",\n",
    "    \"The plot was confusing, and I lost interest quickly.\",\n",
    "    \"The acting was wooden and unconvincing.\",\n",
    "    \"A forgettable experience. I wouldn't watch it again.\",\n",
    "]\n",
    "\n",
    "# Labels (1 for positive, 0 for negative)\n",
    "labels = [1] * len(positive_reviews) + [0] * len(negative_reviews)\n",
    "\n",
    "# Combine positive and negative reviews\n",
    "all_reviews = positive_reviews + negative_reviews\n",
    "\n",
    "# Shuffle the data\n",
    "combined_data = list(zip(all_reviews, labels))\n",
    "random.shuffle(combined_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(combined_data, columns=['text', 'review'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('movie_reviews_dataset.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the data from the CSV file\n",
    "df = pd.read_csv('movie_reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thoroughly enjoyed every moment of the film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The movie was overhyped and did not live up to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great acting and a compelling plot.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A heartwarming and touching film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A masterpiece of storytelling and filmmaking.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The special effects were subpar.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I couldn't wait for it to be over.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The characters were well-developed, and the di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The director did a fantastic job bringing the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A must-watch for all movie enthusiasts.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Incredible visual effects and a gripping narra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I couldn't get enough of this movie. Highly re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I expected more from this movie, but it fell s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>One of the best movies I've seen in years.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The humor in the movie was spot-on and had me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A complete waste of time. I wouldn't recommend...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lackluster performances and a weak plot.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I was disappointed by the lack of depth in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>An instant classic. I will definitely watch it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The plot was confusing, and I lost interest qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I couldn't connect with the characters.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amazing cinematography and excellent performan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The soundtrack added a lot to the overall expe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The movie exceeded my expectations. A true gem.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The twists and turns kept me guessing until th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A brilliant and thought-provoking piece of cin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I regret watching this film.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Disappointing and predictable. Not worth the h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The characters were poorly developed.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Fantastic chemistry among the cast members.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A forgettable experience. I wouldn't watch it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The acting was wooden and unconvincing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The movie was terrible. I didn't enjoy it at all.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I found it boring and uninteresting.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The dialogue felt forced, and the pacing was off.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The film lacked originality and creativity.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I was on the edge of my seat throughout the en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I loved the movie. The storyline was amazing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A letdown from start to finish.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Poor acting and a confusing storyline.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  review\n",
       "0        Thoroughly enjoyed every moment of the film.       1\n",
       "1   The movie was overhyped and did not live up to...       0\n",
       "2                 Great acting and a compelling plot.       1\n",
       "3                   A heartwarming and touching film.       1\n",
       "4       A masterpiece of storytelling and filmmaking.       1\n",
       "5                    The special effects were subpar.       0\n",
       "6                  I couldn't wait for it to be over.       0\n",
       "7   The characters were well-developed, and the di...       1\n",
       "8   The director did a fantastic job bringing the ...       1\n",
       "9             A must-watch for all movie enthusiasts.       1\n",
       "10  Incredible visual effects and a gripping narra...       1\n",
       "11  I couldn't get enough of this movie. Highly re...       1\n",
       "12  I expected more from this movie, but it fell s...       0\n",
       "13         One of the best movies I've seen in years.       1\n",
       "14  The humor in the movie was spot-on and had me ...       1\n",
       "15  A complete waste of time. I wouldn't recommend...       0\n",
       "16           Lackluster performances and a weak plot.       0\n",
       "17  I was disappointed by the lack of depth in the...       0\n",
       "18  An instant classic. I will definitely watch it...       1\n",
       "19  The plot was confusing, and I lost interest qu...       0\n",
       "20            I couldn't connect with the characters.       0\n",
       "21  Amazing cinematography and excellent performan...       1\n",
       "22  The soundtrack added a lot to the overall expe...       1\n",
       "23    The movie exceeded my expectations. A true gem.       1\n",
       "24  The twists and turns kept me guessing until th...       1\n",
       "25  A brilliant and thought-provoking piece of cin...       1\n",
       "26                       I regret watching this film.       0\n",
       "27  Disappointing and predictable. Not worth the h...       0\n",
       "28              The characters were poorly developed.       0\n",
       "29        Fantastic chemistry among the cast members.       1\n",
       "30  A forgettable experience. I wouldn't watch it ...       0\n",
       "31            The acting was wooden and unconvincing.       0\n",
       "32  The movie was terrible. I didn't enjoy it at all.       0\n",
       "33               I found it boring and uninteresting.       0\n",
       "34  The dialogue felt forced, and the pacing was off.       0\n",
       "35        The film lacked originality and creativity.       0\n",
       "36  I was on the edge of my seat throughout the en...       1\n",
       "37      I loved the movie. The storyline was amazing.       1\n",
       "38                    A letdown from start to finish.       0\n",
       "39             Poor acting and a confusing storyline.       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenization, lemmatization, and removal of stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.lower() not in stop_words and token not in punctuation]\n",
    "    return ' '.join(processed_tokens) \n",
    "\n",
    "\n",
    "\n",
    "# Apply preprocessing to all reviews\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Bag-of-Words Representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['processed_text'])\n",
    "y = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60         6\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.50      0.50      0.47         8\n",
      "weighted avg       0.62      0.50      0.53         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Step 8: Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Review:\n",
      "The movie had a captivating storyline and exceptional performances.\n",
      "\n",
      "Predicted Sentiment:\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_review = \"The movie had a captivating storyline and exceptional performances.\"\n",
    "\n",
    "# Preprocess the sample review\n",
    "processed_sample_review = preprocess_text(sample_review)\n",
    "\n",
    "# Convert the processed sample review to a Bag-of-Words representation\n",
    "sample_review_vectorized = vectorizer.transform([processed_sample_review])\n",
    "\n",
    "\n",
    "prediction = classifier.predict(sample_review_vectorized)[0]\n",
    "\n",
    "\n",
    "print(\"Original Review:\")\n",
    "print(sample_review)\n",
    "print(\"\\nPredicted Sentiment:\")\n",
    "if prediction == 1:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
